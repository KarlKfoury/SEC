{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "%run Definitions.py\n",
    "from datetime import datetime, date, timedelta\n",
    "import re\n",
    "import os\n",
    "from collections import *\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract tables from XML content and convert to data frames\n",
    "def extract_tables(xml_content):\n",
    "    soup = BeautifulSoup(xml_content, 'xml')\n",
    "    tables = soup.find_all('infoTable')\n",
    "    data = []\n",
    "    for table in tables:\n",
    "        row = {}\n",
    "        for element in table:\n",
    "            cleaned_text = element.text.strip()\n",
    "            try:\n",
    "                # Decode the text using UTF-8 encoding and ignore any errors\n",
    "                cleaned_text = cleaned_text.encode('utf-8').decode('utf-8', 'ignore')\n",
    "            except UnicodeDecodeError:\n",
    "                pass\n",
    "            \n",
    "            if element.name == 'shrsOrPrnAmt':\n",
    "                # Remove '\\n' from shrsOrPrnAmt column\n",
    "                cleaned_text = cleaned_text.replace('\\n', '')\n",
    "            \n",
    "            if element.name == 'votingAuthority':\n",
    "                # Remove '\\n0\\n0' from the last column\n",
    "                cleaned_text = cleaned_text.replace('\\n0\\n0', '')\n",
    "            \n",
    "            row[element.name] = cleaned_text\n",
    "        data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Function to split shrsOrPrnAmt column into two separate columns\n",
    "def split_shrsOrPrnAmt(df):\n",
    "    df[['shrsOrPrnAmt.sshPrnamt', 'shrsOrPrnAmt.sshPrnamtType']] = df['shrsOrPrnAmt'].str.extract(r'(\\d+)(.*)')\n",
    "    df['shrsOrPrnAmt.sshPrnamt'] = df['shrsOrPrnAmt.sshPrnamt'].str.replace(',', '')  # Remove commas from numbers\n",
    "    df.drop('shrsOrPrnAmt', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Function to extract desired variables from filing text\n",
    "def extract_filing_info(xml_content):\n",
    "    soup = BeautifulSoup(xml_content, 'xml')\n",
    "\n",
    "    # Extract the accession number\n",
    "    sec_document_tag = soup.find('SEC-DOCUMENT')\n",
    "    if sec_document_tag is None:\n",
    "        print(\"Error: <sec-document> tag not found.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    first_line = sec_document_tag.text.strip().split('\\n')[0]\n",
    "    accession_number = first_line.split(':')[0].strip()\n",
    "\n",
    "    # Remove \".txt\" extension from the accession number\n",
    "    accession_number = accession_number.replace('.txt', '')\n",
    "\n",
    "    # print(accession_number)\n",
    "\n",
    "    # Extract CIK (Central Index Key)\n",
    "    cik = soup.find('cik').text.strip()\n",
    "\n",
    "    # Extract filing manager's name\n",
    "    filing_manager_name = soup.find('filingManager').find('name').text.strip()\n",
    "\n",
    "    # Extract period of report\n",
    "    period_of_report = soup.find('periodOfReport').text.strip()\n",
    "\n",
    "    # Parse the date string to a datetime object\n",
    "    period_of_report = datetime.strptime(period_of_report, '%m-%d-%Y')\n",
    "\n",
    "    # Format the date object as SQLite date string\n",
    "    period_of_report = period_of_report.strftime('%Y-%m-%d')\n",
    "\n",
    "    return accession_number, cik, filing_manager_name, period_of_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### USE THIS CODE TO CONVERT date_of_report column in filings from the '%m-%d-%Y' format to the '%Y-%m-%d' format so they can be recognized as dates.\n",
    "\n",
    "# # Connect to the SQLite database\n",
    "# conn = sqlite3.connect(\"/Users/ralph/Biotech/BiotechDatabase.db\") \n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# # Fetch all rows from the filings table\n",
    "# cursor.execute(\"SELECT filing_id, period_of_report FROM filings\")\n",
    "# rows = cursor.fetchall()\n",
    "\n",
    "# # Iterate over the rows and update the period_of_report values\n",
    "# for row in rows:\n",
    "#     filing_id, period_of_report = row\n",
    "\n",
    "#     # Check if the period_of_report is already in the desired format\n",
    "#     if len(period_of_report) == 10:\n",
    "#         try:\n",
    "#             datetime.strptime(period_of_report, '%Y-%m-%d')\n",
    "#             # Skip this row as the date is already in the desired format\n",
    "#             continue\n",
    "#         except ValueError:\n",
    "#             pass\n",
    "\n",
    "#     # Parse the date string to a datetime object\n",
    "#     date_object = datetime.strptime(period_of_report, '%m-%d-%Y')\n",
    "\n",
    "#     # Format the date object as SQLite date string\n",
    "#     sqlite_date = date_object.strftime('%Y-%m-%d')\n",
    "\n",
    "#     # Update the period_of_report value in the table\n",
    "#     cursor.execute(\"UPDATE filings SET period_of_report = ? WHERE filing_id = ?\", (sqlite_date, filing_id))\n",
    "\n",
    "# # Commit the changes and close the connection\n",
    "# conn.commit()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### USE THIS SECTION IF YOU NEED TO DELETE SOME ACCESSION ROWS THAT WERE PARSED BY MISTAKE (LIKE 13F-HR/A FILES)\n",
    "\n",
    "# directory = \"data/13F\"\n",
    "# # processed_directory = 'data/13G_processed'\n",
    "# # # Create the processed directory if it doesn't exist\n",
    "# # os.makedirs(processed_directory, exist_ok=True)\n",
    "\n",
    "# # Get a list of subfolders\n",
    "# subfolders = sorted([f for f in os.listdir(directory) if os.path.isdir(os.path.join(directory, f))], reverse = True)\n",
    "# # subfolders = subfolders[3:4]\n",
    "\n",
    "# print(subfolders)\n",
    "\n",
    "# # Iterate over the subfolders\n",
    "# for subfolder in subfolders:\n",
    "#     print(f'Year being cleaned: {subfolder}')\n",
    "#     subdirectory = os.path.join(directory, subfolder)\n",
    "#     # processed_subdirectory = os.path.join(processed_directory, subfolder)\n",
    "#     # # Create the processed subdirectory if it doesn't exist\n",
    "#     # os.makedirs(processed_subdirectory, exist_ok=True)\n",
    "    \n",
    "#     # Create a list of filingIDs from the data directory\n",
    "#     filingIDs = []\n",
    "#     for filename in os.listdir(subdirectory):\n",
    "#         if filename.endswith(\".txt\"):\n",
    "#             filingID = os.path.splitext(filename)[0]\n",
    "#             filingIDs.append(filingID)\n",
    "#     print(f'Filings in year {subfolder}: {len(filingIDs)}')\n",
    "\n",
    "#     # Connect to the SQLite database and find already parsed filings\n",
    "#     conn = sqlite3.connect(\"/Users/ralph/Biotech/BiotechDatabase.db\") \n",
    "#     cursor = conn.cursor()\n",
    "#     # Get a list of all 13F filingIDs from the SQL table\n",
    "\n",
    "#     cursor.execute(\"SELECT accession FROM SEC_13F_filings\")\n",
    "\n",
    "#     sql_filingIDs_all = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "#     filings_to_delete = list(set(filingIDs) - set(sql_filingIDs_all))\n",
    "\n",
    "#     num_rows_deleted = 0\n",
    "#     num_rows_deleted2 = 0\n",
    "#     # Delete rows where filing_id is in filings_to_delete\n",
    "\n",
    "#     for filing_id in filings_to_delete:\n",
    "#         cursor.execute(\"DELETE FROM filings WHERE filing_id = ?\", (filing_id,))\n",
    "#         num_rows_deleted += cursor.rowcount\n",
    "#         cursor.execute(\"DELETE FROM holdings WHERE filing_id = ?\", (filing_id,))\n",
    "#         num_rows_deleted2 += cursor.rowcount\n",
    "#     cursor.close()\n",
    "#     conn.commit()\n",
    "#     conn.close()\n",
    "#     print(f'Number of rows deleted from filings: {num_rows_deleted}')\n",
    "#     print(f'Number of rows deleted from holdings: {num_rows_deleted2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year being parsed: 2023\n",
      "Filings in year 2023: 20847\n",
      "Filings to parse from intersection: 0\n",
      "Filings to be parsed in year 2023: 1772\n",
      "Year being parsed: 2022\n",
      "Filings in year 2022: 27496\n",
      "Filings to parse from intersection: 0\n",
      "Filings to be parsed in year 2022: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "directory = \"data/13F\"\n",
    "# processed_directory = 'data/13G_processed'\n",
    "# # Create the processed directory if it doesn't exist\n",
    "# os.makedirs(processed_directory, exist_ok=True)\n",
    "\n",
    "# Get a list of subfolders\n",
    "subfolders = sorted([f for f in os.listdir(directory) if os.path.isdir(os.path.join(directory, f))], reverse = True)\n",
    "subfolders = subfolders\n",
    "\n",
    "# print(subfolders)\n",
    "\n",
    "# Iterate over the subfolders\n",
    "for subfolder in subfolders[0:2]:\n",
    "    print(f'Year being parsed: {subfolder}')\n",
    "    subdirectory = os.path.join(directory, subfolder)\n",
    "    # processed_subdirectory = os.path.join(processed_directory, subfolder)\n",
    "    # # Create the processed subdirectory if it doesn't exist\n",
    "    # os.makedirs(processed_subdirectory, exist_ok=True)\n",
    "    \n",
    "    # Create a list of filingIDs from the data directory\n",
    "    filingIDs = []\n",
    "    for filename in os.listdir(subdirectory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filingID = os.path.splitext(filename)[0]\n",
    "            filingIDs.append(filingID)\n",
    "    print(f'Filings in year {subfolder}: {len(filingIDs)}')\n",
    "\n",
    "\n",
    "    # Connect to the SQLite database and find already parsed filings\n",
    "    conn = sqlite3.connect(\"/Users/ralph/Biotech/BiotechDatabase.db\") \n",
    "    cursor = conn.cursor()\n",
    "    # Get a list of parsed 13F filingIDs from the SQL table\n",
    "    cursor.execute(\"SELECT accession FROM SEC_13F_filings WHERE [Parsed 13F] IS NULL OR [Parsed 13F] = ''\")\n",
    "    sql_filingIDs = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "    cursor.execute(\"SELECT accession FROM SEC_13F_filings\")\n",
    "    sql_filingIDs_all = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "    filings_to_parse = list(set(filingIDs).intersection(set(sql_filingIDs)))\n",
    "    print(f'Filings to parse from intersection: {len(filings_to_parse)}')\n",
    "    filings_to_parse.extend(list(set(filingIDs) - set(sql_filingIDs_all)))\n",
    "\n",
    "    print(f'Filings to be parsed in year {subfolder}: {len(filings_to_parse)}')\n",
    "\n",
    "\n",
    "    filing_id_file_with_exception = []\n",
    "    today = date.today()\n",
    "\n",
    "    # Iterate over the files in the directory\n",
    "    for filingID in filings_to_parse:\n",
    "        filename = filingID + '.txt'\n",
    "        file_path = os.path.join(subdirectory, filename)\n",
    "\n",
    "        # Read the file content as UTF-8 encoded text\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Extract tables from the file content\n",
    "        df = extract_tables(content)\n",
    "        if df.empty:\n",
    "            print(f\"No data was generated for file: {filename}.\")\n",
    "            continue\n",
    "\n",
    "        # Split shrsOrPrnAmt column into two separate columns\n",
    "        df = split_shrsOrPrnAmt(df)\n",
    "\n",
    "        if 'nameOfIssuer' in df.columns:\n",
    "            df.rename(columns={'nameOfIssuer': 'name_of_issuer'}, inplace=True)\n",
    "\n",
    "        if 'titleOfClass' in df.columns:\n",
    "            df.rename(columns={'titleOfClass': 'title_of_class'}, inplace=True)\n",
    "\n",
    "        if 'putCall' in df.columns:\n",
    "            df.rename(columns={'putCall': 'put_call'}, inplace=True)\n",
    "        \n",
    "        if 'shrsOrPrnAmt.sshPrnamt' in df.columns:\n",
    "            df.rename(columns={'shrsOrPrnAmt.sshPrnamt': 'shares'}, inplace=True)\n",
    "\n",
    "\n",
    "        columns_to_remove = ['investmentDiscretion', 'votingAuthority', 'shrsOrPrnAmt.sshPrnamtType', 'figi', 'otherManager']\n",
    "        existing_columns = [column for column in columns_to_remove if column in df.columns]\n",
    "        df = df.drop(columns=existing_columns)\n",
    "\n",
    "        df = df.loc[:, df.columns.notnull()]\n",
    "        df['filing_id'] = filingID\n",
    "        df['cusip'] = df['cusip'].str.upper()\n",
    "        df['name_of_issuer'] = df['name_of_issuer'].str.upper()\n",
    "        \n",
    "\n",
    "        # Extract desired filing information\n",
    "        filing_id, cik, filing_manager_name, period_of_report = extract_filing_info(content)\n",
    "\n",
    "        # # Print the extracted information\n",
    "        # print(\"Accession Number:\", filing_id)\n",
    "        # print(\"CIK:\", cik)\n",
    "        # print(\"Filing Manager Name:\", filing_manager_name)\n",
    "        # print(\"Period of Report:\", period_of_report)\n",
    "\n",
    "        filings_sql = \"\"\"\n",
    "                    INSERT OR REPLACE INTO filings (\n",
    "                        filing_id, \n",
    "                        cik,\n",
    "                        filer_name,\n",
    "                        period_of_report\n",
    "                    ) \n",
    "                    VALUES (?,?,?,?)\n",
    "                \"\"\"\n",
    "\n",
    "        try:\n",
    "            conn = sqlite3.connect(\"/Users/ralph/Biotech/BiotechDatabase.db\") \n",
    "            cur = conn.cursor()\n",
    "            #### Insert filings table data\n",
    "            filing_values = (\n",
    "                filing_id,\n",
    "                cik, \n",
    "                filing_manager_name.upper(), # convert all names to upper case to make unique search easier\n",
    "                period_of_report\n",
    "            )\n",
    "            \n",
    "            cur.execute(filings_sql, filing_values)\n",
    "            cur.execute(\"UPDATE SEC_filings SET 'Parsed 13F' = ? WHERE accession = ?\", (today, filingID))\n",
    "            conn.commit()\n",
    "\n",
    "            ##### Insert holdings data\n",
    "            # creating column list for insertion\n",
    "            cols = \"`,`\".join([str(i) for i in df.columns.tolist()])\n",
    "\n",
    "            # Insert DataFrame recrds one by one.\n",
    "            for index,row in df.iterrows():\n",
    "                try:\n",
    "                    cur = conn.cursor()\n",
    "                    sql = \" INSERT OR REPLACE INTO `holdings` (`\" +cols + \"`) VALUES (\" + \"?,\"*(len(row)-1) + \"?)\"\n",
    "                    cur.execute(sql, tuple(row))\n",
    "                    # the connection is not autocommitted by default, so we must commit to save our changes\n",
    "                    # connection.commit()\n",
    "                    conn.commit()\n",
    "                    # cur.close()\n",
    "                except Exception as error:\n",
    "                    print(\"Failed to add row\", error)\n",
    "                    filing_id_file_with_exception.append(row.loc['filing_id'])\n",
    "                    print(index,row)\n",
    "                    pass\n",
    "\n",
    "                \n",
    "        except Exception as error:\n",
    "            print(\"Failed to add file\", error)\n",
    "        finally:\n",
    "            if (conn):\n",
    "                conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
